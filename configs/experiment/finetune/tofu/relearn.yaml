# @package _global_

defaults:
  - override /model: gemma-2-2b
  - override /trainer: relearn
  - override /data/datasets@data.train: TOFU_QA_full
  - override /eval: tofu

mode: finetune
trainer:
  args:
    learning_rate: 1e-5
    weight_decay: 0.0
    warmup_epochs: 0.0 # custom parameter
    num_train_epochs: 1

model:
  model_args:
    pretrained_model_name_or_path: /workspace/open_unlearning/saves/finetune/FINETUNE_GEMMA_TOFU


forget_split: forget10
holdout_split: holdout10
retain_logs_path: null

eval:
  tofu:
    forget_split: ${forget_split}
    holdout_split: ${holdout_split}
    retain_logs_path: ${retain_logs_path}
    overwrite: true


task_name: relearn