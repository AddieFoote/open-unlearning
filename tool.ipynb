{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tasks = ['eval_log', 'eval_real_author_wo_options', 'eval_real_world_wo_options', 'eval_log_forget']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_folder = '/home/pratyus2/scratch/projects/tofu_deploy/unlearn_author/debug/checkpoint-1'\n",
    "eval_result_dict = {}\n",
    "\n",
    "import json \n",
    "\n",
    "for eval_task in eval_tasks:\n",
    "    eval_file = eval_folder + '/' + eval_task + '.json'\n",
    "    with open(eval_file, 'r') as f:\n",
    "        eval_result_dict[f'{eval_task}.json'] = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/retain90_llama_wd0.01/eval_results/ds_size300',\n",
       " 'data/retain95_llama_wd0.01/eval_results/ds_size300',\n",
       " 'data/retain95_phi_wd0.01/eval_results/ds_size300',\n",
       " 'data/retain99_phi_wd0.01/eval_results/ds_size300',\n",
       " 'data/retain99_llama_wd0.01/eval_results/ds_size300',\n",
       " 'data/retain90_phi_wd0.01/eval_results/ds_size300']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "retain_models = os.listdir('data')\n",
    "# get full path of each model\n",
    "eval_paths = [os.path.join('data', model, 'eval_results/ds_size300') for model in retain_models]\n",
    "# delete 'data/idontknow.jsonl/eval_results/ds_size300' from eval_paths\n",
    "eval_paths = [path for path in eval_paths if os.path.exists(path)]\n",
    "eval_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "aggregated_eval_results = {}\n",
    "for eval_path in eval_paths:\n",
    "    for eval_task in eval_tasks:\n",
    "        eval_task_path = os.path.join(eval_path, f'{eval_task}.json')\n",
    "        # read eval result into json\n",
    "        with open(eval_task_path, 'r') as f:\n",
    "            eval_result = json.load(f)\n",
    "            aggregated_eval_results[f'{eval_task}.json'] = eval_result\n",
    "        \n",
    "        with open(os.path.join(eval_path, \"eval_log_aggregated.json\"), 'w') as f:\n",
    "            json.dump(aggregated_eval_results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pratyus2/miniconda3/envs/torch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "real_authors_perturbed = datasets.load_from_disk('/home/pratyus2/scratch/projects/unlearn_author/unlearn_author/validation/filtered_questions_ds_perturbed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 179.89ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17146"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_authors_perturbed.to_json('data/real_authors_perturbed.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 477.22ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18053"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = datasets.load_from_disk('/home/pratyus2/scratch/projects/unlearn_author/unlearn_author/validation/filtered_questions_world_ds_perturbed')\n",
    "ds.to_json('data/world_facts_perturbed.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_tasks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43meval_tasks\u001b[49m \n",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_tasks' is not defined"
     ]
    }
   ],
   "source": [
    "eval_tasks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ks_2samp, hmean\n",
    "def get_metric_values(eval_result_dict):\n",
    "    eval_task_dict = {\n",
    "        'eval_real_author_wo_options.json': 'Real Authors',\n",
    "        'eval_real_world_wo_options.json': 'Real World',\n",
    "        'eval_log.json': 'Retain',\n",
    "        'eval_log_forget.json': 'Forget'\n",
    "    }\n",
    "    eval_tasks = list(eval_task_dict.keys())\n",
    "    metrics = ['ROUGE', 'Probability', 'Truth Ratio']\n",
    "\n",
    "    output_result = {}\n",
    "    for eval_task in eval_tasks:\n",
    "        for metric in metrics:\n",
    "            output_result[eval_task_dict[eval_task] + ' ' + metric] = []\n",
    "\n",
    "    # k is different files\n",
    "    for k, v in eval_result_dict.items():\n",
    "        # getting Probability\n",
    "        if 'eval_log' in k:\n",
    "            gt_probs = np.exp(-1 * np.array(eval_result_dict[k]['avg_gt_loss']))\n",
    "            avg_gt_prob = np.mean(gt_probs)\n",
    "        else:\n",
    "            avg_true_prob = np.exp(-1 * np.array(eval_result_dict[k]['avg_gt_loss']))\n",
    "            avg_false_prob = np.exp(-1 * np.array(eval_result_dict[k]['average_perturb_loss']))\n",
    "            avg_all_prob = np.concatenate([np.expand_dims(avg_true_prob, axis=-1), avg_false_prob], axis=1).sum(-1)\n",
    "            avg_gt_prob = np.mean(avg_true_prob/avg_all_prob)\n",
    "        output_result[f'{eval_task_dict[k]} Probability'] = avg_gt_prob\n",
    "\n",
    "        # getting ROUGE\n",
    "        avg_rouge = np.array(eval_result_dict[k]['rougeL_recall']).mean()\n",
    "        output_result[f'{eval_task_dict[k]} ROUGE'] = avg_rouge\n",
    "\n",
    "        # getting Truth Ratio\n",
    "        avg_paraphrase_np_values = np.array(eval_result_dict[k]['avg_paraphrased_loss'])\n",
    "\n",
    "        avg_perturbed_np_values = np.array(eval_result_dict[k]['average_perturb_loss'])\n",
    "        avg_perturbed_np_values = avg_perturbed_np_values.mean(axis=-1)\n",
    "\n",
    "        curr_stat_1 =  np.exp( avg_perturbed_np_values - avg_paraphrase_np_values)\n",
    "        # output_result[f'{eval_task_dict[k]} paraphrased_over_perturbed'] = curr_stat_1\n",
    "        if 'forget' in k:\n",
    "            paraphrased_perturb_ratio = np.mean(np.minimum(curr_stat_1, 1/curr_stat_1))\n",
    "        else:\n",
    "            paraphrased_perturb_ratio = np.mean(np.maximum(0, 1 - 1/curr_stat_1))\n",
    "        output_result[f'{eval_task_dict[k]} Truth Ratio'] = paraphrased_perturb_ratio\n",
    "\n",
    "    model_utility_cands = []\n",
    "    for k, v in output_result.items():\n",
    "        if 'Forget' not in k:\n",
    "            model_utility_cands.append(v)\n",
    "    output_result['Model Utility'] = hmean(model_utility_cands)\n",
    "    return output_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "eval_result_dict = json.load(open('/home/pratyus2/scratch/projects/tofu_deploy/unlearn_author/debug3/checkpoint-1/eval_log_aggregated.json', 'r'))\n",
    "eval_statistics = get_metric_values(eval_result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Real Authors ROUGE': 0.9329999999999999,\n",
       " 'Real Authors Probability': 0.44677756006386077,\n",
       " 'Real Authors Truth Ratio': 0.5791738109470566,\n",
       " 'Real World ROUGE': 0.8831908831908832,\n",
       " 'Real World Probability': 0.424964976795936,\n",
       " 'Real World Truth Ratio': 0.5577831003415211,\n",
       " 'Retain ROUGE': 0.9820539974079873,\n",
       " 'Retain Probability': 0.989542148533903,\n",
       " 'Retain Truth Ratio': 0.4823950243244189,\n",
       " 'Forget ROUGE': 0.952229742703533,\n",
       " 'Forget Probability': 0.9930274019282684,\n",
       " 'Forget Truth Ratio': 0.534689290778074,\n",
       " 'Model Utility': 0.6242761873861128}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "retain_result_dict = json.load(open('/home/pratyus2/scratch/projects/tofu_deploy/unlearn_author/data/retain90_llama_wd0.01/eval_results/ds_size300/eval_log_aggregated.json', 'r'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forget_quality(unlearn_result, retain_result):\n",
    "    unlearn_forget_result = unlearn_result['eval_log_forget.json']\n",
    "    retain_forget_result = retain_result['eval_log_forget.json']\n",
    "    \n",
    "    unlearn_paraphrase_np_values = np.array(unlearn_forget_result['avg_paraphrased_loss'])\n",
    "    unlearn_perturbed_np_values = np.array(unlearn_forget_result['average_perturb_loss'])\n",
    "    unlearn_perturbed_np_values = unlearn_perturbed_np_values.mean(axis=-1)\n",
    "\n",
    "    retain_paraphrase_np_values = np.array(retain_forget_result['avg_paraphrased_loss'])\n",
    "    retain_perturbed_np_values = np.array(retain_forget_result['average_perturb_loss'])\n",
    "    retain_perturbed_np_values = retain_perturbed_np_values.mean(axis=-1)\n",
    "\n",
    "    unlearn_truth_ratio =  np.exp( unlearn_perturbed_np_values - unlearn_paraphrase_np_values)\n",
    "    retain_truth_ratio =  np.exp( retain_perturbed_np_values - retain_paraphrase_np_values)\n",
    "\n",
    "    test_res = ks_2samp(unlearn_truth_ratio, retain_truth_ratio)\n",
    "    return {'Forget Quality': test_res.pvalue, 'KS Test PVal Forget': test_res.pvalue, 'KS Test Forget': test_res.statistic}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Forget Quality': 2.5867119180804454e-09,\n",
       " 'KS Test PVal Forget': 2.5867119180804454e-09,\n",
       " 'KS Test Forget': 0.5090476190476191}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forget_quality = get_forget_quality(eval_result_dict, retain_result_dict)\n",
    "forget_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pratyus2/miniconda3/envs/torch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/pratyus2/scratch/projects/unlearn_author/unlearn_author/paper_models/final_ft_noLORA_5_epochs_inst_lr2e-05_phi_wd0.01/checkpoint-625 were not used when initializing PhiForCausalLM: ['lm_head.linear.bias', 'lm_head.linear.weight', 'lm_head.ln.bias', 'lm_head.ln.weight', 'transformer.embd.wte.weight', 'transformer.h.0.ln.bias', 'transformer.h.0.ln.weight', 'transformer.h.0.mixer.Wqkv.bias', 'transformer.h.0.mixer.Wqkv.weight', 'transformer.h.0.mixer.out_proj.bias', 'transformer.h.0.mixer.out_proj.weight', 'transformer.h.0.mlp.fc1.bias', 'transformer.h.0.mlp.fc1.weight', 'transformer.h.0.mlp.fc2.bias', 'transformer.h.0.mlp.fc2.weight', 'transformer.h.1.ln.bias', 'transformer.h.1.ln.weight', 'transformer.h.1.mixer.Wqkv.bias', 'transformer.h.1.mixer.Wqkv.weight', 'transformer.h.1.mixer.out_proj.bias', 'transformer.h.1.mixer.out_proj.weight', 'transformer.h.1.mlp.fc1.bias', 'transformer.h.1.mlp.fc1.weight', 'transformer.h.1.mlp.fc2.bias', 'transformer.h.1.mlp.fc2.weight', 'transformer.h.10.ln.bias', 'transformer.h.10.ln.weight', 'transformer.h.10.mixer.Wqkv.bias', 'transformer.h.10.mixer.Wqkv.weight', 'transformer.h.10.mixer.out_proj.bias', 'transformer.h.10.mixer.out_proj.weight', 'transformer.h.10.mlp.fc1.bias', 'transformer.h.10.mlp.fc1.weight', 'transformer.h.10.mlp.fc2.bias', 'transformer.h.10.mlp.fc2.weight', 'transformer.h.11.ln.bias', 'transformer.h.11.ln.weight', 'transformer.h.11.mixer.Wqkv.bias', 'transformer.h.11.mixer.Wqkv.weight', 'transformer.h.11.mixer.out_proj.bias', 'transformer.h.11.mixer.out_proj.weight', 'transformer.h.11.mlp.fc1.bias', 'transformer.h.11.mlp.fc1.weight', 'transformer.h.11.mlp.fc2.bias', 'transformer.h.11.mlp.fc2.weight', 'transformer.h.12.ln.bias', 'transformer.h.12.ln.weight', 'transformer.h.12.mixer.Wqkv.bias', 'transformer.h.12.mixer.Wqkv.weight', 'transformer.h.12.mixer.out_proj.bias', 'transformer.h.12.mixer.out_proj.weight', 'transformer.h.12.mlp.fc1.bias', 'transformer.h.12.mlp.fc1.weight', 'transformer.h.12.mlp.fc2.bias', 'transformer.h.12.mlp.fc2.weight', 'transformer.h.13.ln.bias', 'transformer.h.13.ln.weight', 'transformer.h.13.mixer.Wqkv.bias', 'transformer.h.13.mixer.Wqkv.weight', 'transformer.h.13.mixer.out_proj.bias', 'transformer.h.13.mixer.out_proj.weight', 'transformer.h.13.mlp.fc1.bias', 'transformer.h.13.mlp.fc1.weight', 'transformer.h.13.mlp.fc2.bias', 'transformer.h.13.mlp.fc2.weight', 'transformer.h.14.ln.bias', 'transformer.h.14.ln.weight', 'transformer.h.14.mixer.Wqkv.bias', 'transformer.h.14.mixer.Wqkv.weight', 'transformer.h.14.mixer.out_proj.bias', 'transformer.h.14.mixer.out_proj.weight', 'transformer.h.14.mlp.fc1.bias', 'transformer.h.14.mlp.fc1.weight', 'transformer.h.14.mlp.fc2.bias', 'transformer.h.14.mlp.fc2.weight', 'transformer.h.15.ln.bias', 'transformer.h.15.ln.weight', 'transformer.h.15.mixer.Wqkv.bias', 'transformer.h.15.mixer.Wqkv.weight', 'transformer.h.15.mixer.out_proj.bias', 'transformer.h.15.mixer.out_proj.weight', 'transformer.h.15.mlp.fc1.bias', 'transformer.h.15.mlp.fc1.weight', 'transformer.h.15.mlp.fc2.bias', 'transformer.h.15.mlp.fc2.weight', 'transformer.h.16.ln.bias', 'transformer.h.16.ln.weight', 'transformer.h.16.mixer.Wqkv.bias', 'transformer.h.16.mixer.Wqkv.weight', 'transformer.h.16.mixer.out_proj.bias', 'transformer.h.16.mixer.out_proj.weight', 'transformer.h.16.mlp.fc1.bias', 'transformer.h.16.mlp.fc1.weight', 'transformer.h.16.mlp.fc2.bias', 'transformer.h.16.mlp.fc2.weight', 'transformer.h.17.ln.bias', 'transformer.h.17.ln.weight', 'transformer.h.17.mixer.Wqkv.bias', 'transformer.h.17.mixer.Wqkv.weight', 'transformer.h.17.mixer.out_proj.bias', 'transformer.h.17.mixer.out_proj.weight', 'transformer.h.17.mlp.fc1.bias', 'transformer.h.17.mlp.fc1.weight', 'transformer.h.17.mlp.fc2.bias', 'transformer.h.17.mlp.fc2.weight', 'transformer.h.18.ln.bias', 'transformer.h.18.ln.weight', 'transformer.h.18.mixer.Wqkv.bias', 'transformer.h.18.mixer.Wqkv.weight', 'transformer.h.18.mixer.out_proj.bias', 'transformer.h.18.mixer.out_proj.weight', 'transformer.h.18.mlp.fc1.bias', 'transformer.h.18.mlp.fc1.weight', 'transformer.h.18.mlp.fc2.bias', 'transformer.h.18.mlp.fc2.weight', 'transformer.h.19.ln.bias', 'transformer.h.19.ln.weight', 'transformer.h.19.mixer.Wqkv.bias', 'transformer.h.19.mixer.Wqkv.weight', 'transformer.h.19.mixer.out_proj.bias', 'transformer.h.19.mixer.out_proj.weight', 'transformer.h.19.mlp.fc1.bias', 'transformer.h.19.mlp.fc1.weight', 'transformer.h.19.mlp.fc2.bias', 'transformer.h.19.mlp.fc2.weight', 'transformer.h.2.ln.bias', 'transformer.h.2.ln.weight', 'transformer.h.2.mixer.Wqkv.bias', 'transformer.h.2.mixer.Wqkv.weight', 'transformer.h.2.mixer.out_proj.bias', 'transformer.h.2.mixer.out_proj.weight', 'transformer.h.2.mlp.fc1.bias', 'transformer.h.2.mlp.fc1.weight', 'transformer.h.2.mlp.fc2.bias', 'transformer.h.2.mlp.fc2.weight', 'transformer.h.20.ln.bias', 'transformer.h.20.ln.weight', 'transformer.h.20.mixer.Wqkv.bias', 'transformer.h.20.mixer.Wqkv.weight', 'transformer.h.20.mixer.out_proj.bias', 'transformer.h.20.mixer.out_proj.weight', 'transformer.h.20.mlp.fc1.bias', 'transformer.h.20.mlp.fc1.weight', 'transformer.h.20.mlp.fc2.bias', 'transformer.h.20.mlp.fc2.weight', 'transformer.h.21.ln.bias', 'transformer.h.21.ln.weight', 'transformer.h.21.mixer.Wqkv.bias', 'transformer.h.21.mixer.Wqkv.weight', 'transformer.h.21.mixer.out_proj.bias', 'transformer.h.21.mixer.out_proj.weight', 'transformer.h.21.mlp.fc1.bias', 'transformer.h.21.mlp.fc1.weight', 'transformer.h.21.mlp.fc2.bias', 'transformer.h.21.mlp.fc2.weight', 'transformer.h.22.ln.bias', 'transformer.h.22.ln.weight', 'transformer.h.22.mixer.Wqkv.bias', 'transformer.h.22.mixer.Wqkv.weight', 'transformer.h.22.mixer.out_proj.bias', 'transformer.h.22.mixer.out_proj.weight', 'transformer.h.22.mlp.fc1.bias', 'transformer.h.22.mlp.fc1.weight', 'transformer.h.22.mlp.fc2.bias', 'transformer.h.22.mlp.fc2.weight', 'transformer.h.23.ln.bias', 'transformer.h.23.ln.weight', 'transformer.h.23.mixer.Wqkv.bias', 'transformer.h.23.mixer.Wqkv.weight', 'transformer.h.23.mixer.out_proj.bias', 'transformer.h.23.mixer.out_proj.weight', 'transformer.h.23.mlp.fc1.bias', 'transformer.h.23.mlp.fc1.weight', 'transformer.h.23.mlp.fc2.bias', 'transformer.h.23.mlp.fc2.weight', 'transformer.h.3.ln.bias', 'transformer.h.3.ln.weight', 'transformer.h.3.mixer.Wqkv.bias', 'transformer.h.3.mixer.Wqkv.weight', 'transformer.h.3.mixer.out_proj.bias', 'transformer.h.3.mixer.out_proj.weight', 'transformer.h.3.mlp.fc1.bias', 'transformer.h.3.mlp.fc1.weight', 'transformer.h.3.mlp.fc2.bias', 'transformer.h.3.mlp.fc2.weight', 'transformer.h.4.ln.bias', 'transformer.h.4.ln.weight', 'transformer.h.4.mixer.Wqkv.bias', 'transformer.h.4.mixer.Wqkv.weight', 'transformer.h.4.mixer.out_proj.bias', 'transformer.h.4.mixer.out_proj.weight', 'transformer.h.4.mlp.fc1.bias', 'transformer.h.4.mlp.fc1.weight', 'transformer.h.4.mlp.fc2.bias', 'transformer.h.4.mlp.fc2.weight', 'transformer.h.5.ln.bias', 'transformer.h.5.ln.weight', 'transformer.h.5.mixer.Wqkv.bias', 'transformer.h.5.mixer.Wqkv.weight', 'transformer.h.5.mixer.out_proj.bias', 'transformer.h.5.mixer.out_proj.weight', 'transformer.h.5.mlp.fc1.bias', 'transformer.h.5.mlp.fc1.weight', 'transformer.h.5.mlp.fc2.bias', 'transformer.h.5.mlp.fc2.weight', 'transformer.h.6.ln.bias', 'transformer.h.6.ln.weight', 'transformer.h.6.mixer.Wqkv.bias', 'transformer.h.6.mixer.Wqkv.weight', 'transformer.h.6.mixer.out_proj.bias', 'transformer.h.6.mixer.out_proj.weight', 'transformer.h.6.mlp.fc1.bias', 'transformer.h.6.mlp.fc1.weight', 'transformer.h.6.mlp.fc2.bias', 'transformer.h.6.mlp.fc2.weight', 'transformer.h.7.ln.bias', 'transformer.h.7.ln.weight', 'transformer.h.7.mixer.Wqkv.bias', 'transformer.h.7.mixer.Wqkv.weight', 'transformer.h.7.mixer.out_proj.bias', 'transformer.h.7.mixer.out_proj.weight', 'transformer.h.7.mlp.fc1.bias', 'transformer.h.7.mlp.fc1.weight', 'transformer.h.7.mlp.fc2.bias', 'transformer.h.7.mlp.fc2.weight', 'transformer.h.8.ln.bias', 'transformer.h.8.ln.weight', 'transformer.h.8.mixer.Wqkv.bias', 'transformer.h.8.mixer.Wqkv.weight', 'transformer.h.8.mixer.out_proj.bias', 'transformer.h.8.mixer.out_proj.weight', 'transformer.h.8.mlp.fc1.bias', 'transformer.h.8.mlp.fc1.weight', 'transformer.h.8.mlp.fc2.bias', 'transformer.h.8.mlp.fc2.weight', 'transformer.h.9.ln.bias', 'transformer.h.9.ln.weight', 'transformer.h.9.mixer.Wqkv.bias', 'transformer.h.9.mixer.Wqkv.weight', 'transformer.h.9.mixer.out_proj.bias', 'transformer.h.9.mixer.out_proj.weight', 'transformer.h.9.mlp.fc1.bias', 'transformer.h.9.mlp.fc1.weight', 'transformer.h.9.mlp.fc2.bias', 'transformer.h.9.mlp.fc2.weight']\n",
      "- This IS expected if you are initializing PhiForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing PhiForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of PhiForCausalLM were not initialized from the model checkpoint at /home/pratyus2/scratch/projects/unlearn_author/unlearn_author/paper_models/final_ft_noLORA_5_epochs_inst_lr2e-05_phi_wd0.01/checkpoint-625 and are newly initialized: ['embed_tokens.weight', 'final_layernorm.bias', 'final_layernorm.weight', 'layers.0.input_layernorm.bias', 'layers.0.input_layernorm.weight', 'layers.0.mlp.fc1.bias', 'layers.0.mlp.fc1.weight', 'layers.0.mlp.fc2.bias', 'layers.0.mlp.fc2.weight', 'layers.0.self_attn.dense.bias', 'layers.0.self_attn.dense.weight', 'layers.0.self_attn.k_proj.bias', 'layers.0.self_attn.k_proj.weight', 'layers.0.self_attn.q_proj.bias', 'layers.0.self_attn.q_proj.weight', 'layers.0.self_attn.v_proj.bias', 'layers.0.self_attn.v_proj.weight', 'layers.1.input_layernorm.bias', 'layers.1.input_layernorm.weight', 'layers.1.mlp.fc1.bias', 'layers.1.mlp.fc1.weight', 'layers.1.mlp.fc2.bias', 'layers.1.mlp.fc2.weight', 'layers.1.self_attn.dense.bias', 'layers.1.self_attn.dense.weight', 'layers.1.self_attn.k_proj.bias', 'layers.1.self_attn.k_proj.weight', 'layers.1.self_attn.q_proj.bias', 'layers.1.self_attn.q_proj.weight', 'layers.1.self_attn.v_proj.bias', 'layers.1.self_attn.v_proj.weight', 'layers.10.input_layernorm.bias', 'layers.10.input_layernorm.weight', 'layers.10.mlp.fc1.bias', 'layers.10.mlp.fc1.weight', 'layers.10.mlp.fc2.bias', 'layers.10.mlp.fc2.weight', 'layers.10.self_attn.dense.bias', 'layers.10.self_attn.dense.weight', 'layers.10.self_attn.k_proj.bias', 'layers.10.self_attn.k_proj.weight', 'layers.10.self_attn.q_proj.bias', 'layers.10.self_attn.q_proj.weight', 'layers.10.self_attn.v_proj.bias', 'layers.10.self_attn.v_proj.weight', 'layers.11.input_layernorm.bias', 'layers.11.input_layernorm.weight', 'layers.11.mlp.fc1.bias', 'layers.11.mlp.fc1.weight', 'layers.11.mlp.fc2.bias', 'layers.11.mlp.fc2.weight', 'layers.11.self_attn.dense.bias', 'layers.11.self_attn.dense.weight', 'layers.11.self_attn.k_proj.bias', 'layers.11.self_attn.k_proj.weight', 'layers.11.self_attn.q_proj.bias', 'layers.11.self_attn.q_proj.weight', 'layers.11.self_attn.v_proj.bias', 'layers.11.self_attn.v_proj.weight', 'layers.12.input_layernorm.bias', 'layers.12.input_layernorm.weight', 'layers.12.mlp.fc1.bias', 'layers.12.mlp.fc1.weight', 'layers.12.mlp.fc2.bias', 'layers.12.mlp.fc2.weight', 'layers.12.self_attn.dense.bias', 'layers.12.self_attn.dense.weight', 'layers.12.self_attn.k_proj.bias', 'layers.12.self_attn.k_proj.weight', 'layers.12.self_attn.q_proj.bias', 'layers.12.self_attn.q_proj.weight', 'layers.12.self_attn.v_proj.bias', 'layers.12.self_attn.v_proj.weight', 'layers.13.input_layernorm.bias', 'layers.13.input_layernorm.weight', 'layers.13.mlp.fc1.bias', 'layers.13.mlp.fc1.weight', 'layers.13.mlp.fc2.bias', 'layers.13.mlp.fc2.weight', 'layers.13.self_attn.dense.bias', 'layers.13.self_attn.dense.weight', 'layers.13.self_attn.k_proj.bias', 'layers.13.self_attn.k_proj.weight', 'layers.13.self_attn.q_proj.bias', 'layers.13.self_attn.q_proj.weight', 'layers.13.self_attn.v_proj.bias', 'layers.13.self_attn.v_proj.weight', 'layers.14.input_layernorm.bias', 'layers.14.input_layernorm.weight', 'layers.14.mlp.fc1.bias', 'layers.14.mlp.fc1.weight', 'layers.14.mlp.fc2.bias', 'layers.14.mlp.fc2.weight', 'layers.14.self_attn.dense.bias', 'layers.14.self_attn.dense.weight', 'layers.14.self_attn.k_proj.bias', 'layers.14.self_attn.k_proj.weight', 'layers.14.self_attn.q_proj.bias', 'layers.14.self_attn.q_proj.weight', 'layers.14.self_attn.v_proj.bias', 'layers.14.self_attn.v_proj.weight', 'layers.15.input_layernorm.bias', 'layers.15.input_layernorm.weight', 'layers.15.mlp.fc1.bias', 'layers.15.mlp.fc1.weight', 'layers.15.mlp.fc2.bias', 'layers.15.mlp.fc2.weight', 'layers.15.self_attn.dense.bias', 'layers.15.self_attn.dense.weight', 'layers.15.self_attn.k_proj.bias', 'layers.15.self_attn.k_proj.weight', 'layers.15.self_attn.q_proj.bias', 'layers.15.self_attn.q_proj.weight', 'layers.15.self_attn.v_proj.bias', 'layers.15.self_attn.v_proj.weight', 'layers.16.input_layernorm.bias', 'layers.16.input_layernorm.weight', 'layers.16.mlp.fc1.bias', 'layers.16.mlp.fc1.weight', 'layers.16.mlp.fc2.bias', 'layers.16.mlp.fc2.weight', 'layers.16.self_attn.dense.bias', 'layers.16.self_attn.dense.weight', 'layers.16.self_attn.k_proj.bias', 'layers.16.self_attn.k_proj.weight', 'layers.16.self_attn.q_proj.bias', 'layers.16.self_attn.q_proj.weight', 'layers.16.self_attn.v_proj.bias', 'layers.16.self_attn.v_proj.weight', 'layers.17.input_layernorm.bias', 'layers.17.input_layernorm.weight', 'layers.17.mlp.fc1.bias', 'layers.17.mlp.fc1.weight', 'layers.17.mlp.fc2.bias', 'layers.17.mlp.fc2.weight', 'layers.17.self_attn.dense.bias', 'layers.17.self_attn.dense.weight', 'layers.17.self_attn.k_proj.bias', 'layers.17.self_attn.k_proj.weight', 'layers.17.self_attn.q_proj.bias', 'layers.17.self_attn.q_proj.weight', 'layers.17.self_attn.v_proj.bias', 'layers.17.self_attn.v_proj.weight', 'layers.18.input_layernorm.bias', 'layers.18.input_layernorm.weight', 'layers.18.mlp.fc1.bias', 'layers.18.mlp.fc1.weight', 'layers.18.mlp.fc2.bias', 'layers.18.mlp.fc2.weight', 'layers.18.self_attn.dense.bias', 'layers.18.self_attn.dense.weight', 'layers.18.self_attn.k_proj.bias', 'layers.18.self_attn.k_proj.weight', 'layers.18.self_attn.q_proj.bias', 'layers.18.self_attn.q_proj.weight', 'layers.18.self_attn.v_proj.bias', 'layers.18.self_attn.v_proj.weight', 'layers.19.input_layernorm.bias', 'layers.19.input_layernorm.weight', 'layers.19.mlp.fc1.bias', 'layers.19.mlp.fc1.weight', 'layers.19.mlp.fc2.bias', 'layers.19.mlp.fc2.weight', 'layers.19.self_attn.dense.bias', 'layers.19.self_attn.dense.weight', 'layers.19.self_attn.k_proj.bias', 'layers.19.self_attn.k_proj.weight', 'layers.19.self_attn.q_proj.bias', 'layers.19.self_attn.q_proj.weight', 'layers.19.self_attn.v_proj.bias', 'layers.19.self_attn.v_proj.weight', 'layers.2.input_layernorm.bias', 'layers.2.input_layernorm.weight', 'layers.2.mlp.fc1.bias', 'layers.2.mlp.fc1.weight', 'layers.2.mlp.fc2.bias', 'layers.2.mlp.fc2.weight', 'layers.2.self_attn.dense.bias', 'layers.2.self_attn.dense.weight', 'layers.2.self_attn.k_proj.bias', 'layers.2.self_attn.k_proj.weight', 'layers.2.self_attn.q_proj.bias', 'layers.2.self_attn.q_proj.weight', 'layers.2.self_attn.v_proj.bias', 'layers.2.self_attn.v_proj.weight', 'layers.20.input_layernorm.bias', 'layers.20.input_layernorm.weight', 'layers.20.mlp.fc1.bias', 'layers.20.mlp.fc1.weight', 'layers.20.mlp.fc2.bias', 'layers.20.mlp.fc2.weight', 'layers.20.self_attn.dense.bias', 'layers.20.self_attn.dense.weight', 'layers.20.self_attn.k_proj.bias', 'layers.20.self_attn.k_proj.weight', 'layers.20.self_attn.q_proj.bias', 'layers.20.self_attn.q_proj.weight', 'layers.20.self_attn.v_proj.bias', 'layers.20.self_attn.v_proj.weight', 'layers.21.input_layernorm.bias', 'layers.21.input_layernorm.weight', 'layers.21.mlp.fc1.bias', 'layers.21.mlp.fc1.weight', 'layers.21.mlp.fc2.bias', 'layers.21.mlp.fc2.weight', 'layers.21.self_attn.dense.bias', 'layers.21.self_attn.dense.weight', 'layers.21.self_attn.k_proj.bias', 'layers.21.self_attn.k_proj.weight', 'layers.21.self_attn.q_proj.bias', 'layers.21.self_attn.q_proj.weight', 'layers.21.self_attn.v_proj.bias', 'layers.21.self_attn.v_proj.weight', 'layers.22.input_layernorm.bias', 'layers.22.input_layernorm.weight', 'layers.22.mlp.fc1.bias', 'layers.22.mlp.fc1.weight', 'layers.22.mlp.fc2.bias', 'layers.22.mlp.fc2.weight', 'layers.22.self_attn.dense.bias', 'layers.22.self_attn.dense.weight', 'layers.22.self_attn.k_proj.bias', 'layers.22.self_attn.k_proj.weight', 'layers.22.self_attn.q_proj.bias', 'layers.22.self_attn.q_proj.weight', 'layers.22.self_attn.v_proj.bias', 'layers.22.self_attn.v_proj.weight', 'layers.23.input_layernorm.bias', 'layers.23.input_layernorm.weight', 'layers.23.mlp.fc1.bias', 'layers.23.mlp.fc1.weight', 'layers.23.mlp.fc2.bias', 'layers.23.mlp.fc2.weight', 'layers.23.self_attn.dense.bias', 'layers.23.self_attn.dense.weight', 'layers.23.self_attn.k_proj.bias', 'layers.23.self_attn.k_proj.weight', 'layers.23.self_attn.q_proj.bias', 'layers.23.self_attn.q_proj.weight', 'layers.23.self_attn.v_proj.bias', 'layers.23.self_attn.v_proj.weight', 'layers.3.input_layernorm.bias', 'layers.3.input_layernorm.weight', 'layers.3.mlp.fc1.bias', 'layers.3.mlp.fc1.weight', 'layers.3.mlp.fc2.bias', 'layers.3.mlp.fc2.weight', 'layers.3.self_attn.dense.bias', 'layers.3.self_attn.dense.weight', 'layers.3.self_attn.k_proj.bias', 'layers.3.self_attn.k_proj.weight', 'layers.3.self_attn.q_proj.bias', 'layers.3.self_attn.q_proj.weight', 'layers.3.self_attn.v_proj.bias', 'layers.3.self_attn.v_proj.weight', 'layers.4.input_layernorm.bias', 'layers.4.input_layernorm.weight', 'layers.4.mlp.fc1.bias', 'layers.4.mlp.fc1.weight', 'layers.4.mlp.fc2.bias', 'layers.4.mlp.fc2.weight', 'layers.4.self_attn.dense.bias', 'layers.4.self_attn.dense.weight', 'layers.4.self_attn.k_proj.bias', 'layers.4.self_attn.k_proj.weight', 'layers.4.self_attn.q_proj.bias', 'layers.4.self_attn.q_proj.weight', 'layers.4.self_attn.v_proj.bias', 'layers.4.self_attn.v_proj.weight', 'layers.5.input_layernorm.bias', 'layers.5.input_layernorm.weight', 'layers.5.mlp.fc1.bias', 'layers.5.mlp.fc1.weight', 'layers.5.mlp.fc2.bias', 'layers.5.mlp.fc2.weight', 'layers.5.self_attn.dense.bias', 'layers.5.self_attn.dense.weight', 'layers.5.self_attn.k_proj.bias', 'layers.5.self_attn.k_proj.weight', 'layers.5.self_attn.q_proj.bias', 'layers.5.self_attn.q_proj.weight', 'layers.5.self_attn.v_proj.bias', 'layers.5.self_attn.v_proj.weight', 'layers.6.input_layernorm.bias', 'layers.6.input_layernorm.weight', 'layers.6.mlp.fc1.bias', 'layers.6.mlp.fc1.weight', 'layers.6.mlp.fc2.bias', 'layers.6.mlp.fc2.weight', 'layers.6.self_attn.dense.bias', 'layers.6.self_attn.dense.weight', 'layers.6.self_attn.k_proj.bias', 'layers.6.self_attn.k_proj.weight', 'layers.6.self_attn.q_proj.bias', 'layers.6.self_attn.q_proj.weight', 'layers.6.self_attn.v_proj.bias', 'layers.6.self_attn.v_proj.weight', 'layers.7.input_layernorm.bias', 'layers.7.input_layernorm.weight', 'layers.7.mlp.fc1.bias', 'layers.7.mlp.fc1.weight', 'layers.7.mlp.fc2.bias', 'layers.7.mlp.fc2.weight', 'layers.7.self_attn.dense.bias', 'layers.7.self_attn.dense.weight', 'layers.7.self_attn.k_proj.bias', 'layers.7.self_attn.k_proj.weight', 'layers.7.self_attn.q_proj.bias', 'layers.7.self_attn.q_proj.weight', 'layers.7.self_attn.v_proj.bias', 'layers.7.self_attn.v_proj.weight', 'layers.8.input_layernorm.bias', 'layers.8.input_layernorm.weight', 'layers.8.mlp.fc1.bias', 'layers.8.mlp.fc1.weight', 'layers.8.mlp.fc2.bias', 'layers.8.mlp.fc2.weight', 'layers.8.self_attn.dense.bias', 'layers.8.self_attn.dense.weight', 'layers.8.self_attn.k_proj.bias', 'layers.8.self_attn.k_proj.weight', 'layers.8.self_attn.q_proj.bias', 'layers.8.self_attn.q_proj.weight', 'layers.8.self_attn.v_proj.bias', 'layers.8.self_attn.v_proj.weight', 'layers.9.input_layernorm.bias', 'layers.9.input_layernorm.weight', 'layers.9.mlp.fc1.bias', 'layers.9.mlp.fc1.weight', 'layers.9.mlp.fc2.bias', 'layers.9.mlp.fc2.weight', 'layers.9.self_attn.dense.bias', 'layers.9.self_attn.dense.weight', 'layers.9.self_attn.k_proj.bias', 'layers.9.self_attn.k_proj.weight', 'layers.9.self_attn.q_proj.bias', 'layers.9.self_attn.q_proj.weight', 'layers.9.self_attn.v_proj.bias', 'layers.9.self_attn.v_proj.weight', 'lm_head.bias', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained('microsoft/phi-1_5')\n",
    "model = AutoModelForCausalLM.from_pretrained('/home/pratyus2/scratch/projects/unlearn_author/unlearn_author/paper_models/final_ft_noLORA_5_epochs_inst_lr2e-05_phi_wd0.01/checkpoint-625', config=config, trust_remote_code=True, torch_dtype=torch.bfloat16).cuda(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.57s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model = AutoModelForCausalLM.from_pretrained('/home/pratyus2/scratch/projects/unlearn_author/unlearn_author/paper_models/final_ft_noLORA_5_epochs_inst_lr1e-05_llama2-7b_wd0.01/checkpoint-625', trust_remote_code=True, torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/phi-1_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pratyus2/miniconda3/envs/torch/lib/python3.10/site-packages/transformers/generation/utils.py:1518: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/home/pratyus2/miniconda3/envs/torch/lib/python3.10/site-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer('The quick brown fox jumps over the lazy dog', return_tensors='pt').input_ids.cuda(2)\n",
    "generation = model.generate(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The quick brown fox jumps over the lazy dogorous Cruz02 brid verses Jobs prototypes artific artific artific artific'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generation[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
